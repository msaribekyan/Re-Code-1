{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "WmWUMRLXNrBJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "mfPbmb5bCknr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
        "    words = text.split()\n",
        "    return ' '.join(lemmatizer.lemmatize(w) for w in words if w.isalpha())\n",
        "\n",
        "train_csv = pd.read_csv(\"https://raw.githubusercontent.com/msaribekyan/Re-Code-1/refs/heads/main/data/dataset_C_train.csv\")\n",
        "val_csv = pd.read_csv(\"https://raw.githubusercontent.com/msaribekyan/Re-Code-1/refs/heads/main/data/dataset_C_val.csv\")\n",
        "\n",
        "X_raw_train = train_csv['text']\n",
        "y_train = train_csv.drop('text', axis=1)\n",
        "\n",
        "X_train = []\n",
        "\n",
        "for index, row in X_raw_train.items():\n",
        "  X_train.append(lemmatize_text(row))\n",
        "\n",
        "X_raw_val = val_csv['text']\n",
        "y_val = val_csv.drop('text', axis=1)\n",
        "\n",
        "X_val = []\n",
        "\n",
        "for index, row in X_raw_val.items():\n",
        "  X_val.append(lemmatize_text(row))\n"
      ],
      "metadata": {
        "id": "Q5nXXge4CrMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de6515c-15f7-4991-f7db-a8d7b6f6a0ee"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization"
      ],
      "metadata": {
        "id": "wFRLtCUAnW-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_features=30000)\n",
        "\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_val = tfidf.transform(X_val)\n",
        "\n",
        "joblib.dump(tfidf, \"tfidf.pkl\")"
      ],
      "metadata": {
        "id": "A7mCMpAQnbou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ef910e-81f5-4a43-c14f-8a58b95d568b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "g-bErn0sncQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = MultiOutputClassifier(LogisticRegression())\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(model, \"model.pkl\")"
      ],
      "metadata": {
        "id": "T-ETwTcenlGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01d327a-5be7-45f4-b145-d09e42f4f364"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "kDjVGH1Anekj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_predict = model.predict(X_val)\n",
        "\n",
        "print(\"Metrics for Label 1\")\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_val['label_1'], y_predict[:, 0]))\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_val['label_1'], y_predict[:, 0]))\n",
        "\n",
        "print(\"Metrics for Label 2\")\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_val['label_2'], y_predict[:, 1]))\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_val['label_2'], y_predict[:, 1]))\n",
        "\n",
        "print(\"Metrics for Label 3\")\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_val['label_3'], y_predict[:, 2]))\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_val['label_3'], y_predict[:, 2]))\n",
        "\n",
        "print(\"Metrics for Label 4\")\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_val['label_4'], y_predict[:, 3]))\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_val['label_4'], y_predict[:, 3]))\n"
      ],
      "metadata": {
        "id": "vE3xJLvDngXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5941eb9-3ab9-4fcd-dda1-e74c08a870bb"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Label 1\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88        78\n",
            "           1       0.85      0.85      0.85        62\n",
            "\n",
            "    accuracy                           0.87       140\n",
            "   macro avg       0.87      0.87      0.87       140\n",
            "weighted avg       0.87      0.87      0.87       140\n",
            "\n",
            "Confusion matrix:\n",
            "[[69  9]\n",
            " [ 9 53]]\n",
            "Metrics for Label 2\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.38      0.53        58\n",
            "           1       0.69      0.96      0.80        82\n",
            "\n",
            "    accuracy                           0.72       140\n",
            "   macro avg       0.78      0.67      0.67       140\n",
            "weighted avg       0.77      0.72      0.69       140\n",
            "\n",
            "Confusion matrix:\n",
            "[[22 36]\n",
            " [ 3 79]]\n",
            "Metrics for Label 3\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.87      0.81        63\n",
            "           1       0.88      0.78      0.83        77\n",
            "\n",
            "    accuracy                           0.82       140\n",
            "   macro avg       0.82      0.83      0.82       140\n",
            "weighted avg       0.83      0.82      0.82       140\n",
            "\n",
            "Confusion matrix:\n",
            "[[55  8]\n",
            " [17 60]]\n",
            "Metrics for Label 4\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.95      0.84        76\n",
            "           1       0.91      0.62      0.74        64\n",
            "\n",
            "    accuracy                           0.80       140\n",
            "   macro avg       0.83      0.79      0.79       140\n",
            "weighted avg       0.82      0.80      0.79       140\n",
            "\n",
            "Confusion matrix:\n",
            "[[72  4]\n",
            " [24 40]]\n"
          ]
        }
      ]
    }
  ]
}